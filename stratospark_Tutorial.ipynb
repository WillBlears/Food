{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stratospark_Tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WillBlears/Food/blob/master/stratospark_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2fJFw8vARRuW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Possible issues\n",
        "\n",
        "- files get put into wrong order when they are split"
      ]
    },
    {
      "metadata": {
        "id": "_9xgVBLcx7nR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "metadata": {
        "id": "a3C8c9_Np7Fq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# May contain repeats\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "import collections\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import matplotlib.image as img\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import numpy as np\n",
        "from scipy.misc import imresize\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import shutil\n",
        "import stat\n",
        "import collections\n",
        "from collections import defaultdict\n",
        "\n",
        "from ipywidgets import interact, interactive, fixed\n",
        "import ipywidgets as widgets\n",
        "\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DjiiWKiUzNAW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Setup"
      ]
    },
    {
      "metadata": {
        "id": "M9q7RTyhx8XH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download and unpack Food-101\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
        "!tar xzvf food-101.tar.gz\n",
        "# Tools\n",
        "!wget https://raw.githubusercontent.com/stratospark/food-101-keras/master/tools/image_gen_extended.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g204DQjyZ7FP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Unzip uploaded data\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('food-101_reduced.zip', 'r')\n",
        "zip_ref.extractall('')\n",
        "zip_ref.close()\n",
        "# Tools\n",
        "wget https://raw.githubusercontent.com/stratospark/food-101-keras/master/tools/image_gen_extended.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8mif1GpibNhl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Delete folder\n",
        "shutil.rmtree('delete_me')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eNgNmHXVylVR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make reduced size dataset with split .txt files\n",
        "\n",
        "# Delete folder\n",
        "#shutil.rmtree('food-101_reduced')\n",
        "\n",
        "root = 'food-101'\n",
        "new_dir = 'food-101_reduced'\n",
        "size = 75\n",
        "\n",
        "os.mkdir(new_dir)\n",
        "os.mkdir(new_dir + '/images')\n",
        "os.mkdir(new_dir + '/meta')\n",
        "copyfile(root + '/meta/classes.txt', new_dir + '/meta/classes.txt')\n",
        "copyfile(root + '/meta/labels.txt', new_dir + '/meta/labels.txt')\n",
        "f_train = open(new_dir + '/meta/train.txt', 'a+')\n",
        "f_test = open(new_dir + '/meta/test.txt', 'a+')\n",
        "\n",
        "for dirName, subdirList, fileList in os.walk(root + '/images'):\n",
        "  for class_name in subdirList:\n",
        "    print('Copying:' + class_name)\n",
        "    os.mkdir(new_dir + '/images/' + class_name)\n",
        "    images = os.listdir('food-101/images/' + class_name)\n",
        "    for im in range(size):\n",
        "      copyfile(root + '/images/' + class_name + '/' + images[im], new_dir + '/images/' + class_name + '/' + images[im])\n",
        "      if(im < size/4):\n",
        "        id = class_name + '/' + images[im]\n",
        "        f_test.write(id[:-4] + '\\n')\n",
        "      else:\n",
        "        id = class_name + '/' + images[im]\n",
        "        f_train.write(id[:-4] + '\\n')\n",
        "        \n",
        "f_train.close()\n",
        "f_test.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQ_uGHaMebpK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# zip folder for download\n",
        "!zip -r food-101_reduced food-101_reduced"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nrfM1XlNksnO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# No longer need to run this!!!\n",
        "# Split images\n",
        "\n",
        "root = 'food-101_reduced'\n",
        "\n",
        "# Delete folders\n",
        "#shutil.rmtree(root + '/train')\n",
        "#shutil.rmtree(root + '/test')\n",
        "\n",
        "os.mkdir(root + '/train')\n",
        "os.mkdir(root + '/test')\n",
        "\n",
        "for dirName, subdirList, fileList in os.walk(root + '/images'):\n",
        "  for class_name in subdirList:\n",
        "    print('Copying:' + class_name)\n",
        "    os.mkdir(root + '/train/' + class_name)\n",
        "    os.mkdir(root + '/test/' + class_name)\n",
        "    images = os.listdir('food-101/images/' + class_name)\n",
        "    for im in range(int(size/4)):\n",
        "      copyfile(root + '/images/' + class_name + '/' + images[im], new_dir + '/test/' + class_name + '/' + images[im])\n",
        "    for im in range(int(size/4), size):\n",
        "      copyfile(root + '/images/' + class_name + '/' + images[im], new_dir + '/train/' + class_name + '/' + images[im])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7dJjLTaDzpYq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stratospark Code"
      ]
    },
    {
      "metadata": {
        "id": "tjRYXSvnIK4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Setup multiprocessing pool\n",
        "# Do this early, as once images are loaded into memory there will be Errno 12\n",
        "# http://stackoverflow.com/questions/14749897/python-multiprocessing-memory-usage\n",
        "import multiprocessing as mp\n",
        "\n",
        "num_processes = 6\n",
        "pool = mp.Pool(processes=num_processes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2BKQA1zYzz1f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Maps from class to index and Vice Versa\n",
        "\n",
        "class_to_ix = {}\n",
        "ix_to_class = {}\n",
        "with open('food-101_reduced/meta/classes.txt', 'r') as txt:\n",
        "    classes = [l.strip() for l in txt.readlines()]\n",
        "    class_to_ix = dict(zip(classes, range(len(classes))))\n",
        "    ix_to_class = dict(zip(range(len(classes)), classes))\n",
        "    class_to_ix = {v: k for k, v in ix_to_class.items()}\n",
        "sorted_class_to_ix = collections.OrderedDict(sorted(class_to_ix.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LUAWhdrDVZl5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Only split files if haven't already\n",
        "if not os.path.isdir('./food-101_reduced/test') and not os.path.isdir('./food-101_reduced/train'):\n",
        "\n",
        "    def copytree(src, dst, symlinks = False, ignore = None):\n",
        "        if not os.path.exists(dst):\n",
        "            os.makedirs(dst)\n",
        "            shutil.copystat(src, dst)\n",
        "        lst = os.listdir(src)\n",
        "        if ignore:\n",
        "            excl = ignore(src, lst)\n",
        "            lst = [x for x in lst if x not in excl]\n",
        "        for item in lst:\n",
        "            s = os.path.join(src, item)\n",
        "            d = os.path.join(dst, item)\n",
        "            if symlinks and os.path.islink(s):\n",
        "                if os.path.lexists(d):\n",
        "                    os.remove(d)\n",
        "                os.symlink(os.readlink(s), d)\n",
        "                try:\n",
        "                    st = os.lstat(s)\n",
        "                    mode = stat.S_IMODE(st.st_mode)\n",
        "                    os.lchmod(d, mode)\n",
        "                except:\n",
        "                    pass # lchmod not available\n",
        "            elif os.path.isdir(s):\n",
        "                copytree(s, d, symlinks, ignore)\n",
        "            else:\n",
        "               shutil.copy2(s, d)\n",
        "\n",
        "    def generate_dir_file_map(path):\n",
        "        dir_files = defaultdict(list)\n",
        "        with open(path, 'r') as txt:\n",
        "            files = [l.strip() for l in txt.readlines()]\n",
        "            for f in files:\n",
        "                dir_name, id = f.split('/')\n",
        "                dir_files[dir_name].append(id + '.jpg')\n",
        "        return dir_files\n",
        "\n",
        "    train_dir_files = generate_dir_file_map('food-101_reduced/meta/train.txt')\n",
        "    test_dir_files = generate_dir_file_map('food-101_reduced/meta/test.txt')\n",
        "\n",
        "\n",
        "    def ignore_train(d, filenames):\n",
        "        print(d)\n",
        "        subdir = d.split('/')[-1]\n",
        "        to_ignore = train_dir_files[subdir]\n",
        "        return to_ignore\n",
        "\n",
        "    def ignore_test(d, filenames):\n",
        "        print(d)\n",
        "        subdir = d.split('/')[-1]\n",
        "        to_ignore = test_dir_files[subdir]\n",
        "        return to_ignore\n",
        "\n",
        "    copytree('food-101_reduced/images', 'food-101_reduced/test', ignore=ignore_train)\n",
        "    copytree('food-101_reduced/images', 'food-101_reduced/train', ignore=ignore_test)\n",
        "    \n",
        "else:\n",
        "    print('Train/Test files already copied into separate folders.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FFNbSdHKkNWW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = 'food-101_reduced'\n",
        "\n",
        "test_path = PATH+'/test/'\n",
        "train_path = PATH+'/train/'\n",
        "train_batch = os.listdir(train_path)\n",
        "x_train = []\n",
        "  \n",
        "# if data are in form of images\n",
        "for sample in train_batch:\n",
        "  img_path = train_path + sample\n",
        "  print(sample)\n",
        "  x = image.load_img(img_path)\n",
        "  # preprocessing if required\n",
        "  x_train.append(x)\n",
        " \n",
        "test_path = PATH+'/test/'\n",
        "test_batch = os.listdir(test_path)\n",
        "x_test = []\n",
        " \n",
        "for sample in test_path:\n",
        "\timg_path = test_path+sample\n",
        "\tx = image.load_img(img_path)\n",
        "\t# preprocessing if required\n",
        "\tx_test.append(x)\n",
        "\t\n",
        "# finally converting list into numpy array\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PpIbcfAD0eub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load dataset images and resize to meet minimum width and height pixel size\n",
        "def load_images(root, min_side=299):\n",
        "    all_imgs = []\n",
        "    all_classes = []\n",
        "    resize_count = 0\n",
        "    invalid_count = 0\n",
        "    for i, subdir in enumerate(listdir(root)):\n",
        "        imgs = listdir(join(root, subdir))\n",
        "        class_ix = class_to_ix[subdir]\n",
        "        print(i, class_ix, subdir)\n",
        "        for img_name in imgs:\n",
        "            img_arr = img.imread(join(root, subdir, img_name))\n",
        "            img_arr_rs = img_arr\n",
        "            try:\n",
        "                w, h, _ = img_arr.shape\n",
        "                if w < min_side:\n",
        "                    wpercent = (min_side/float(w))\n",
        "                    hsize = int((float(h)*float(wpercent)))\n",
        "                    #print('new dims:', min_side, hsize)\n",
        "                    img_arr_rs = imresize(img_arr, (min_side, hsize))\n",
        "                    resize_count += 1\n",
        "                elif h < min_side:\n",
        "                    hpercent = (min_side/float(h))\n",
        "                    wsize = int((float(w)*float(hpercent)))\n",
        "                    #print('new dims:', wsize, min_side)\n",
        "                    img_arr_rs = imresize(img_arr, (wsize, min_side))\n",
        "                    resize_count += 1\n",
        "                all_imgs.append(img_arr_rs)\n",
        "                all_classes.append(class_ix)\n",
        "            except:\n",
        "                print('Skipping bad image: ', subdir, img_name)\n",
        "                invalid_count += 1\n",
        "    print(len(all_imgs), 'images loaded')\n",
        "    print(resize_count, 'images resized')\n",
        "    print(invalid_count, 'images skipped')\n",
        "    return np.array(all_imgs), np.array(all_classes)\n",
        "  \n",
        "  \n",
        "# Execute load_images\n",
        "\n",
        "X_test, y_test = load_images('food-101_reduced/test', min_side=299)\n",
        "X_train, y_train = load_images('food-101_reduced/train', min_side=299)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ecg_1IbB64Mu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('X_train shape', X_train.shape)\n",
        "print('y_train shape', y_train.shape)\n",
        "print('X_test shape', X_test.shape)\n",
        "print('y_test shape', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZ2McAQ7-5yN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualisation tool\n",
        "\n",
        "@interact(n=(0, len(X_train)))\n",
        "def show_pic(n):\n",
        "    plt.imshow(X_train[n])\n",
        "    print('class:', y_train[n], ix_to_class[y_train[n]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zVMAFb5f_32y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualisation tool\n",
        "\n",
        "@interact(n_class=sorted_class_to_ix)\n",
        "def show_random_images_of_class(n_class=0):\n",
        "    print(n_class)\n",
        "    nrows = 4\n",
        "    ncols = 8\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
        "    fig.set_size_inches(12, 8)\n",
        "    #fig.tight_layout()\n",
        "    imgs = np.random.choice((y_train == n_class).nonzero()[0], nrows * ncols)\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        im = ax.imshow(X_train[imgs[i]])\n",
        "        ax.set_axis_off()\n",
        "        ax.title.set_visible(False)\n",
        "        ax.xaxis.set_ticks([])\n",
        "        ax.yaxis.set_ticks([])\n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_visible(False)\n",
        "    plt.subplots_adjust(left=0, wspace=0, hspace=0)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I4O5xUKbAoTP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Image Augmentation\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "n_classes = 101\n",
        "#y_train_cat = to_categorical(y_train, nb_classes=n_classes)\n",
        "#y_test_cat = to_categorical(y_test, nb_classes=n_classes)\n",
        "y_train_cat = to_categorical(y_train, n_classes)\n",
        "y_test_cat = to_categorical(y_test, n_classes)\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input\n",
        "\n",
        "import image_gen_extended as T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35tLOGUJD9G3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = T.ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False, # randomly flip images\n",
        "    zoom_range=[.8, 1],\n",
        "    channel_shift_range=30,\n",
        "    fill_mode='reflect')\n",
        "train_datagen.config['random_crop_size'] = (299, 299)\n",
        "train_datagen.set_pipeline([T.random_transform, T.random_crop, T.preprocess_input])\n",
        "train_generator = train_datagen.flow(X_train, y_train_cat, batch_size=64, seed=11, pool=pool)\n",
        "\n",
        "test_datagen = T.ImageDataGenerator()\n",
        "test_datagen.config['random_crop_size'] = (299, 299)\n",
        "test_datagen.set_pipeline([T.random_transform, T.random_crop, T.preprocess_input])\n",
        "test_generator = test_datagen.flow(X_test, y_test_cat, batch_size=64, seed=11, pool=pool)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9iP6hiGDTayJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fix for pickling error >> https://github.com/stratospark/food-101-keras/issues/10\n",
        "\n",
        "import copy_reg\n",
        "import types\n",
        "import multiprocessing\n",
        "\n",
        "def _pickle_method(m):\n",
        "    if m.im_self is None:\n",
        "        return getattr, (m.im_class, m.im_func.func_name)\n",
        "    else:\n",
        "        return getattr, (m.im_self, m.im_func.func_name)\n",
        "\n",
        "copy_reg.pickle(types.MethodType, _pickle_method)\n",
        "\n",
        "def reverse_preprocess_input(x0):\n",
        "    x = x0 / 2.0\n",
        "    x += 0.5\n",
        "    x *= 255.\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pRsO_yLQEIe_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  @interact()\n",
        "def show_images(unprocess=True):\n",
        "    for x in test_generator:\n",
        "        fig, axes = plt.subplots(nrows=8, ncols=4)\n",
        "        fig.set_size_inches(8, 8)\n",
        "        page = 0\n",
        "        page_size = 32\n",
        "        start_i = page * page_size\n",
        "        for i, ax in enumerate(axes.flat):\n",
        "            img = x[0][i+start_i]\n",
        "            if unprocess:\n",
        "                im = ax.imshow( reverse_preprocess_input(img).astype('uint8') )\n",
        "            else:\n",
        "                im = ax.imshow(img)\n",
        "            ax.set_axis_off()\n",
        "            ax.title.set_visible(False)\n",
        "            ax.xaxis.set_ticks([])\n",
        "            ax.yaxis.set_ticks([])\n",
        "            for spine in ax.spines.values():\n",
        "                spine.set_visible(False)\n",
        "\n",
        "        plt.subplots_adjust(left=0, wspace=0, hspace=0)\n",
        "        plt.show()\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GDKfI1vcIiou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Not working\n",
        "\n",
        "%%time\n",
        "show_images(unprocess=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMPX_GsWJarj",
        "colab_type": "code",
        "outputId": "554aeefe-fa50-4dca-e6c2-585a4fc568e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "\n",
        "%%time\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.optimizers import SGD\n",
        "from keras.regularizers import l2\n",
        "import keras.backend as K\n",
        "import math\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=Input(shape=(299, 299, 3)))\n",
        "x = base_model.output\n",
        "x = AveragePooling2D(pool_size=(8, 8))(x)\n",
        "x = Dropout(.4)(x)\n",
        "x = Flatten()(x)\n",
        "predictions = Dense(n_classes, init='glorot_uniform', W_regularizer=l2(.0005), activation='softmax')(x)\n",
        "\n",
        "model = Model(input=base_model.input, output=predictions)\n",
        "\n",
        "opt = SGD(lr=.01, momentum=.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model4.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=True)\n",
        "csv_logger = CSVLogger('model4.log')\n",
        "\n",
        "def schedule(epoch):\n",
        "    if epoch < 15:\n",
        "        return .01\n",
        "    elif epoch < 28:\n",
        "        return .002\n",
        "    else:\n",
        "        return .0004\n",
        "lr_scheduler = LearningRateScheduler(schedule)\n",
        "\n",
        "model.fit_generator(train_generator,\n",
        "                    validation_data=test_generator,\n",
        "                    nb_val_samples=X_test.shape[0],\n",
        "                    samples_per_epoch=X_train.shape[0],\n",
        "                    nb_epoch=32,\n",
        "                    verbose=2,\n",
        "                    callbacks=[lr_scheduler, csv_logger, checkpointer])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 2s 0us/step\n",
            "87924736/87910968 [==============================] - 2s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(101, kernel_regularizer=<keras.reg..., activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:44: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<image_gen..., verbose=2, validation_data=<image_gen..., steps_per_epoch=89, epochs=32, callbacks=[<keras.ca..., validation_steps=1818)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uSsgrFN5q7ix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "    \n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "    \n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)  \n",
        "\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BGPT-d5CswO7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bwyp_JFztEAb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJeaGH_otTqi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}